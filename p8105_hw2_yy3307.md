p8105_hw2_yy3307
================
Yang Yi
2022-09-28

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

Importing and cleaning data tables: This
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv` dataset contains
information related to entrance and exit conditions for each subway
stations in NYC. The dataset contains character variables, double class
variables which holds double-precision floating point numbers, and
logical variables. To clean-up the dataset, firstly I need to import the
data. Then I used `janitor::clean_names` function to clean up variable
names. The next step is to select variables and discard others using
`select` function. I also changed the data type of route 8-11 into
character for consistency with route 1-7. In order to convert one
variable from character to logical variable, I mutate the character
variables of “YES and NO” into logical conditions `TRUE and FALSE`.

``` r
transit_df = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, exit_only, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, `YES` = TRUE, `NO` = FALSE))
```

Currently the dimension of dateset is 1868\*19, which has 1868 rows and
19 columns. But the dataset is not tidy yet, we can modify the route
1-11 columns from wide to long format to make them become variables in a
single column.

To find distinct stations from transit_df dataset, we can use `distinct`
function to summarize all distinct variable combinations and then count
number of rows in the new dataset.

``` r
dist_station = nrow(distinct(transit_df, station_name, line))
```

*We can tell that there are 465 distinct stations.*

Then, we would like to know how many distinct stations are ADA
compliant. It’s similar with previous question but this time the data we
want must satisfy the condition that `ada == TRUE`, so we can use
`filter` function to select data that satisfy the condition and find
`distinct` combinations from these data. Lastly, we also need to use
`nrow` to count for numbers of distinct combinations.

``` r
ada_compliant = nrow(distinct(filter(transit_df, ada == TRUE), station_name, line))
```

*We find that 84 stations are ADA compliant.*

In order to calculate the proportion of station entrances / exits
without vending allow entrance, we need to use the number of stations
`without vending allow entrance` divided by number of stations
`without vending`. Also, I’ll use filter function to create constraints.

``` r
entrance_without_vending = nrow(filter(transit_df, vending == "NO", entry == TRUE))
proportion = entrance_without_vending / nrow(filter(transit_df, vending == "NO"))
```

*In conclusion, 0.38 (rounded by 2 decimal places) of station entrances
/ exits without vending allow entrance.*

Lastly, I’m going to use `pivot_longer` function to transform route
number and route name into distinct variables with long format. After
modifying route name and value, I’ll `filter` the `distinct` stations
that satisfy `route == "A"` condition for distinct stations serve the A
train and `filter` the `distinct` stations that satisfy `route == "A"`
and `ada == TRUE` condition for ADA compliant stations that serve A
train.

``` r
pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>%
  filter(route == "A") %>%
  distinct(station_name, line)
```

    ## # A tibble: 60 × 2
    ##    line            station_name                 
    ##    <chr>           <chr>                        
    ##  1 42nd St Shuttle Times Square                 
    ##  2 8 Avenue        125th St                     
    ##  3 8 Avenue        145th St                     
    ##  4 8 Avenue        14th St                      
    ##  5 8 Avenue        168th St - Washington Heights
    ##  6 8 Avenue        175th St                     
    ##  7 8 Avenue        181st St                     
    ##  8 8 Avenue        190th St                     
    ##  9 8 Avenue        34th St                      
    ## 10 8 Avenue        42nd St                      
    ## # … with 50 more rows

*There are **60** distinct stations serve the A train.*

``` r
pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>%
  filter(route == "A", ada == TRUE) %>%
  distinct(station_name, line)
```

    ## # A tibble: 17 × 2
    ##    line             station_name                 
    ##    <chr>            <chr>                        
    ##  1 8 Avenue         14th St                      
    ##  2 8 Avenue         168th St - Washington Heights
    ##  3 8 Avenue         175th St                     
    ##  4 8 Avenue         34th St                      
    ##  5 8 Avenue         42nd St                      
    ##  6 8 Avenue         59th St                      
    ##  7 8 Avenue         Inwood - 207th St            
    ##  8 8 Avenue         West 4th St                  
    ##  9 8 Avenue         World Trade Center           
    ## 10 Broadway         Times Square-42nd St         
    ## 11 Broadway-7th Ave 59th St-Columbus Circle      
    ## 12 Broadway-7th Ave Times Square                 
    ## 13 Canarsie         8th Av                       
    ## 14 Franklin         Franklin Av                  
    ## 15 Fulton           Euclid Av                    
    ## 16 Fulton           Franklin Av                  
    ## 17 Rockaway         Howard Beach

*Of the stations that serve the A train, **17** of them are ADA
compliant.*

# Problem 2

To tidy `Mr. Trash Wheel` and `Professor Trash Wheel` datasets, firstly
we need to import and clean the `data/Trash Wheel Collection Data.xlsx`
dataset, the table is in excel format so we need to call `readxl` from
library. To eliminate rows with figure and notes, we can directly select
desired data variables from excel sheet. After cleaning column variable
names, we’ll use `drop_na` to omit rows that no not include `dumpster`
data. Then, we need to `mutate` the `sports_ball` variable into integers
and `round` them to the nearest integer. Lastly, I added a data column
of `data_source` to keep track the source of data.

``` r
trash_df =
  read_excel(
    "data/Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
  select(dumpster:homes_powered) %>%
  mutate(data_source = "Mr. Trash Wheel") %>%
  select(data_source, everything()) %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)))

pro_trash_df =
  read_excel(
    "data/Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel") %>%
  janitor::clean_names() %>%
  select(dumpster:homes_powered) %>%
  mutate(data_source = "Professor Trash Wheel") %>%
  select(data_source, everything()) %>%
  mutate(year = as.character(year)) %>%
  drop_na(dumpster)
```

After cleaning both datasets, I’m going to combine these two datasets to
produce a single tidy dataset. In order to keep all important
information from both datasets, I’ll use `full_join` for combination.

``` r
combine_trash_df = full_join(trash_df, pro_trash_df)
```

*After combination, we get a 641 \* 15 tidy dataset, including
`data_source, dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered`.
Specifically, we observed 453 groups of data for Mr. Trash Wheel from
May 2014 to January 2021, and 71 observations for Professor Trash Wheel
from January 2017 to January 2021. Using this dataset, we can easily
find total numbers of any trash collections that we’re interested in.
For instance, the total number of glass bottles collected by Professor
Trash Wheel is 1429. Or we can find the mean value of specific sampled
data, such as the mean value of polystyrene collection for Mr. Trash
Wheel in May is 2136.25.*

*The total weight of trash collected by Professor Trash Wheel is 190.12
tons. And the total number of sports balls collected by Mr. Trash Wheel
in 2020 is 856.*

# Problem 3

Firstly we need to read and import the
`fivethirtyeight_datasets/pols-month.csv` file and clean it. I’ll
separate the “mon” variable into “year”, “month”, “day” variables using
“-” as separation notations. Then we can use `recode` function to
replace month number with month name. To create president variable
taking gop and dem, I would set the president become a copy of either
`prez_dem` or `prez_gop` columns. This way the president variable will
contain numbers of 0 and 1, so that I can determine whether the
president is gop or dem (1 = yes, 0 = no) using `recode`. Lastly, we can
use select to keep the variables we want in order and eliminate others.
I also transfer the data type of `year` variable in `pols` dataset from
“character” to “double” to keep the consistence between datasets.

``` r
pols_df =
  read_csv(file = "./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(
    month = recode(month, `01` = "January", `02` = "February", `03` = "March", `04` = "April", `05` = "May", `06` = "June", `07` = "July", `08` = "August", `09` = "September", `10` = "October", `11` = "November", `12` = "December",)) %>%
  mutate(
    president = prez_gop,
    president = recode(president, `0` = "dem", `1` = "gop")) %>%
  mutate(year = as.double(year)) %>%
  select(year, month, gov_gop:rep_gop, gov_dem:president)
```

After importing and cleaning `snp.csv` dataset, I found that the `year`
variable automatically keeps the last two digits and discard the first
two. For consistency across datasets, I considered the year variable as
numeric and use an `ifelse` condition to present the `year` variable
back to 4 digits (if two digits year is greater than or euqal to 50,
then it’s in 20th century; other conditions will be considered as 21st
century). Then we need to `recode` month variable from numbers to names
and re-arrange dataset as we want.

``` r
snp_df =
  read_csv(file = "./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(
    year = as.integer(year),
    year = ifelse(year >= 50, year + 1900, year + 2000)) %>%
  select(year, month, close) %>%
  arrange(year, as.integer(month)) %>%
  mutate(
    month = recode(month, `1` = "January", `2` = "February", `3` = "March", `4` = "April", `5` = "May", `6` = "June", `7` = "July", `8` = "August", `9` = "September", `10` = "October", `11` = "November", `12` = "December",)
  )
```

The `unemployment.csv` dataset is in wide format with `month` as column
names, so we need to use `pivot_longer` to transfer it into long format.
We also need to `recode` month variable from numbers to names. Since the
data has already been arranged, we don’t need to re-arrange this time.

``` r
unemploy_df =
  read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment%") %>%
  mutate(
    month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December",)
  )
```

Lastly we’ll `join` three datasets into one complete result by year and
month. To keep all data information, I’m going to use `full_join`
function.

``` r
full_data = full_join(pols_df, snp_df)
full_data = full_join(full_data, unemploy_df)
```

*The “pols-month” dataset contains 822 observations of 9 variables
related to the number of national politicians who are democratic or
republican at any given time. After modification, the dataset contains
`year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president`
as variables. “gov/sen/rep_gop/dem” indicates the number of
republican/democratic governors/senators/representatives on the
associated date, and “prez_gop/dem” is an indicator of whether the
president was republican/democratic on the associated date. The result
dataset has a dimension of 822 \* 9, with the range of years from 1947
to 2015.*

*The “snp” dataset contains 787 observations of 2 variables related to
S&P stock market index. After modification, the dataset contains
`year, month, close` as variables. The result dataset has a dimension of
787 \* 3, with the range of years from 1950 to 2015.*

*The “unemployment” dataset contains 68 observations of 13 variables
rekated to percentage of unemployment in each month of the associated
year. After modification, the dataset contains
`year, month, unemployment%` as variables. The result dataset has a
dimension of 816 \* 3, with the range of years from 1948 to 2015.*

*After combination, we merged all important data into one single
“full_data” dataset, which has a dimension of 828 \* 11. All of the key
variables from three datasets are collected in this file, so we have
`year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, close, unemployment%`
as variables. And the range of years is from 1947 to 2015.*
