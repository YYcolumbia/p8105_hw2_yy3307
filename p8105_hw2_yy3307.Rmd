---
title: "p8105_hw2_yy3307"
output: github_document
date: "2022-09-28"
author: "Yang Yi"
UNI: "yy3307"
---

```{r setup, message = FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

Importing and cleaning data tables:
This `NYC_Transit_Subway_Entrance_And_Exit_Data.csv` dataset contains information related to entrance and exit conditions for each subway stations in NYC. The dataset contains character variables, double class variables which holds double-precision floating point numbers, and logical variables. To clean-up the dataset, firstly I need to import the data. Then I used `janitor::clean_names` function to clean up variable names. The next step is to select variables and discard others using `select` function. I also changed the data type of route 8-11 into character for consistency with route 1-7. In order to convert one variable from character to logical variable, I mutate the character variables of "YES and NO" into logical conditions `TRUE and FALSE`.

```{r import}
transit_df = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, exit_only, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, `YES` = TRUE, `NO` = FALSE))
```

Currently the dimension of dateset is 1868*19, which has 1868 rows and 19 columns. But the dataset is not tidy yet, we can modify the route 1-11 columns from wide to long format to make them become variables in a single column.

To find distinct stations from transit_df dataset, we can use `distinct` function to summarize all distinct variable combinations and then count number of rows in the new dataset. 

```{r distinct}
dist_station = nrow(distinct(transit_df, station_name, line))
```

_We can tell that there are `r dist_station` distinct stations._

Then, we would like to know how many distinct stations are ADA compliant. It's similar with previous question but this time the data we want must satisfy the condition that `ada == TRUE`, so we can use `filter` function to select data  that satisfy the condition and find `distinct` combinations from these data. Lastly, we also need to use `nrow` to count for numbers of distinct combinations. 

```{r ada}
ada_compliant = nrow(distinct(filter(transit_df, ada == TRUE), station_name, line))
```

_We find that `r ada_compliant` stations are ADA compliant._

In order to calculate the proportion of station entrances / exits without vending allow entrance, we need to use the number of stations `without vending allow entrance` divided by number of stations `without vending`. Also, I'll use filter function to create constraints. 

```{r proportion}
entrance_without_vending = nrow(filter(transit_df, vending == "NO", entry == TRUE))
proportion = entrance_without_vending / nrow(filter(transit_df, vending == "NO"))
```

_In conclusion, `r round(proportion, digits = 2)` (rounded by 2 decimal places) of station entrances / exits without vending allow entrance._

Lastly, I'm going to use `pivot_longer` function to transform route number and route name into distinct variables with long format. After modifying route name and value, I'll `filter` the `distinct` stations that satisfy `route == "A"` condition for distinct stations serve the A train and `filter` the `distinct` stations that satisfy `route == "A"` and `ada == TRUE` condition for ADA compliant stations that serve A train.

```{r rounteA}
pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>%
  filter(route == "A") %>%
  distinct(station_name, line)
```

_There are **60** distinct stations serve the A train._

```{r routeA_ada}
pivot_longer(
    transit_df,
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>%
  filter(route == "A", ada == TRUE) %>%
  distinct(station_name, line)
```

_Of the stations that serve the A train, **17** of them are ADA compliant._

# Problem 2

To tidy `Mr. Trash Wheel` and `Professor Trash Wheel` datasets, firstly we need to import and clean the `data/Trash Wheel Collection Data.xlsx` dataset, the table is in excel format so we need to call `readxl` from library. To eliminate rows with figure and notes, we can directly select desired data variables from excel sheet. After cleaning column variable names, we'll use `drop_na` to omit rows that no not include `dumpster` data. Then, we need to `mutate` the `sports_ball` variable into integers and `round` them to the nearest integer. Lastly, I added a data column of `data_source` to keep track the source of data.

```{r trash, message = FALSE}
trash_df =
  read_excel(
    "data/Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
  select(dumpster:homes_powered) %>%
  mutate(data_source = "Mr. Trash Wheel") %>%
  select(data_source, everything()) %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)))

pro_trash_df =
  read_excel(
    "data/Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel") %>%
  janitor::clean_names() %>%
  select(dumpster:homes_powered) %>%
  mutate(data_source = "Professor Trash Wheel") %>%
  select(data_source, everything()) %>%
  mutate(year = as.character(year)) %>%
  drop_na(dumpster)
```

After cleaning both datasets, I'm going to combine these two datasets to produce a single tidy dataset. In order to keep all important information from both datasets, I'll use `full_join` for combination. 

```{r combine_trashes, message = FALSE}
combine_trash_df = full_join(trash_df, pro_trash_df)
```

```{r, echo = FALSE}
row_combine = nrow(combine_trash_df)
col_combine = ncol(combine_trash_df)

professor_glass = colSums(combine_trash_df[548:641, c("glass_bottles")])
trash_may_poly = colMeans(combine_trash_df[1:8, c("polystyrene")])

total_professor = colSums(combine_trash_df[548:641, c("weight_tons")])
sports_trash = colSums(combine_trash_df[381:452, c("sports_balls")])
```

_After combination, we get a `r row_combine` * `r col_combine` tidy dataset, including `data_source, dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered`. Specifically, we observed 453 groups of data for Mr. Trash Wheel from May 2014 to January 2021, and 71 observations for Professor Trash Wheel from January 2017 to January 2021. Using this dataset, we can easily find total numbers of any trash collections that we're interested in. For instance, the total number of glass bottles collected by Professor Trash Wheel is `r professor_glass`. Or we can find the mean value of specific sampled data, such as the mean value of polystyrene collection for Mr. Trash Wheel in May is `r trash_may_poly`._

_The total weight of trash collected by Professor Trash Wheel is `r total_professor` tons. And the total number of sports balls collected by Mr. Trash Wheel in 2020 is `r sports_trash`._

# Problem 3

Firstly we need to read and import the `fivethirtyeight_datasets/pols-month.csv` file and clean it. I'll separate the "mon" variable into "year", "month", "day" variables using "-" as separation notations. Then we can use `recode` function to replace month number with month name. To create president variable taking gop and dem, I would set the president become a copy of either `prez_dem` or `prez_gop` columns. This way the president variable will contain numbers of 0 and 1, so that I can determine whether the president is gop or dem (1 = yes, 0 = no) using `recode`. Lastly, we can use select to keep the variables we want in order and eliminate others. I also transfer the data type of `year` variable in `pols` dataset from "character" to "double" to keep the consistence between datasets.

```{r pol, message = FALSE, warning = FALSE}
pols_df =
  read_csv(file = "./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(
    month = recode(month, `01` = "January", `02` = "February", `03` = "March", `04` = "April", `05` = "May", `06` = "June", `07` = "July", `08` = "August", `09` = "September", `10` = "October", `11` = "November", `12` = "December",)) %>%
  mutate(
    president = prez_gop,
    president = recode(president, `0` = "dem", `1` = "gop")) %>%
  mutate(year = as.double(year)) %>%
  select(year, month, gov_gop:rep_gop, gov_dem:president)
```

After importing and cleaning `snp.csv` dataset, I found that the `year` variable automatically keeps the last two digits and discard the first two. For consistency across datasets, I considered the year variable as numeric and use an `ifelse` condition to present the `year` variable back to 4 digits (if two digits year is greater than or euqal to 50, then it's in 20th century; other conditions will be considered as 21st century). Then we need to `recode` month variable from numbers to names and re-arrange dataset as we want.

```{r snp, message = FALSE}
snp_df =
  read_csv(file = "./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(
    year = as.integer(year),
    year = ifelse(year >= 50, year + 1900, year + 2000)) %>%
  select(year, month, close) %>%
  arrange(year, as.integer(month)) %>%
  mutate(
    month = recode(month, `1` = "January", `2` = "February", `3` = "March", `4` = "April", `5` = "May", `6` = "June", `7` = "July", `8` = "August", `9` = "September", `10` = "October", `11` = "November", `12` = "December",)
  )
```

The `unemployment.csv` dataset is in wide format with `month` as column names, so we need to use `pivot_longer` to transfer it into long format. We also need to `recode` month variable from numbers to names. Since the data has already been arranged, we don't need to re-arrange this time.

```{r unemployment, message = FALSE}
unemploy_df =
  read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment%") %>%
  mutate(
    month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June", "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December",)
  )
```

Lastly we'll `join` three datasets into one complete result by year and month. To keep all data information, I'm going to use `full_join` function.

```{r join, message = FALSE}
full_data = full_join(pols_df, snp_df)
full_data = full_join(full_data, unemploy_df)
```

```{r, echo = FALSE}
row_pols = nrow(pols_df)
col_pols = ncol(pols_df)

row_snp = nrow(snp_df)
col_snp = ncol(snp_df)

row_unemploy = nrow(unemploy_df)
col_unemploy = ncol(unemploy_df)

row_full = nrow(full_data)
col_full = ncol(full_data)
```

_The "pols-month" dataset contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time. After modification, the dataset contains `year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president` as variables. "gov/sen/rep_gop/dem" indicates the number of republican/democratic  governors/senators/representatives on the associated date, and "prez_gop/dem" is an indicator of whether the president was republican/democratic on the associated date. The result dataset has a dimension of `r row_pols` * `r col_pols`, with the range of years from 1947 to 2015._

_The "snp" dataset contains 787 observations of 2 variables related to S&P stock market index. After modification, the dataset contains `year, month, close` as variables. The result dataset has a dimension of `r row_snp` * `r col_snp`, with the range of years from 1950 to 2015._

_The "unemployment" dataset contains  68 observations of 13 variables rekated to percentage of unemployment in each month of the associated year. After modification, the dataset contains `year, month, unemployment%` as variables. The result dataset has a dimension of `r row_unemploy` * `r col_unemploy`, with the range of years from 1948 to 2015._

_After combination, we merged all important data into one single "full_data" dataset, which has a dimension of `r row_full` * `r col_full`. All of the key variables from three datasets are collected in this file, so we have `year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, close, unemployment%` as variables. And the range of years is from 1947 to 2015._